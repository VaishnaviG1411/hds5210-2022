{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Working with a database\n",
    "\n",
    "This week's assignment has a few basic steps.  First, we're going to pull some data down off the internet and store it into our MySQL database.  Make sure that you use your username as part of the table name as show in the examples so that you don't create a problem for other students.\n",
    "\n",
    "Then, we'll merge that with some data already in the database and calculate a few results.  When it comes to calculating the results, you can do so either with SQL or with Pandas operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 1: Setup your database connection and table name\n",
    "\n",
    "In the code below, change the value of the variable `MYTABLE` to use your own username rather that `'pboal'`\n",
    "\n",
    "You can then use `MYTABLE` in the rest of your code to reference that table name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "myname = getpass.getuser().split('-')[1]\n",
    "myname\n",
    "MYTABLE=myname + '_data'\n",
    "\n",
    "host = 'slucor2022-instance-1.cgdcoitnku0k.us-east-1.rds.amazonaws.com'\n",
    "port = \"3306\"\n",
    "username = 'slucor2022'\n",
    "password = \"SLUcor2022\"\n",
    "database = \"hds5210\"\n",
    "\n",
    "conn = create_engine(\"mysql+pymysql://\" + username + \":\" + password + \"@\" + host + \"/\" + database, echo = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q01-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(MYTABLE != 'pboal')\n",
    "assert(conn.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 2: Bring in outside data\n",
    "\n",
    "Grab the data from this URL and put it into a database table named with your `username_data`.\n",
    "\n",
    "https://opendata.arcgis.com/api/v3/datasets/ed0bc689bde246b18835c7529ba4efb4_0/downloads/data?format=csv&spatialRefId=4326\n",
    "\n",
    "By the end of your cell, the table should be created.  The tests are going to verify that the table exists and looks right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'vaishnavig1411_data' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3575abdbe50f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://opendata.arcgis.com/api/v3/datasets/ed0bc689bde246b18835c7529ba4efb4_0/downloads/data?format=csv&spatialRefId=4326\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMYTABLE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2613\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2614\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2615\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2616\u001b[0m         )\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         )\n\u001b[0;32m-> 1393\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fail\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Table 'vaishnavig1411_data' already exists."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://opendata.arcgis.com/api/v3/datasets/ed0bc689bde246b18835c7529ba4efb4_0/downloads/data?format=csv&spatialRefId=4326\")\n",
    "df.to_sql(MYTABLE, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q02-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dxyz = pd.read_sql_query('SELECT * FROM ' + MYTABLE, conn)\n",
    "assert(dxyz.shape == (323,22))\n",
    "assert(list(dxyz.columns) == ['index', 'X', 'Y', 'OBJECTID', 'Provider_Name', 'NPI', 'CCN',\n",
    "       'Business_Street_Address', 'Business_City', 'Business_County',\n",
    "       'Business_ZIP_Code', 'Business_State_Territory', 'Payment_Year_Number',\n",
    "       'Program_Type', 'Medicaid_EP_Hospital_Type', 'total_payments',\n",
    "       'Last_Payment_Criteria', 'Recent_Disbursement_Amount', 'Latitude',\n",
    "       'Longitude', 'Last_Program_Year', 'Last_Payment_Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q03-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 3: Combine with other data in the database\n",
    "\n",
    "In the database, there is an existing table called `population`.  We want to merge the DHCS datafile loaded above with the population data available in this other database table  The tables can be merged on `MYTABLE`'s `Business_ZIP_Code` field and `population`'s `Zip` field.\n",
    "\n",
    "Note that not all `Zip_Codes` from your downloaded file have to be in the `population` table.  If they aren't, then I want you to eliminate the non-matching records.  That is, only keep the records that have a matching ZIP code in both sets of data.\n",
    "\n",
    "Answer the question:\n",
    "Which providers are located in the zipcode with the largest population?\n",
    "\n",
    "Put your answer in the form `answer = ['a', 'list', 'of', 'NPI', 'like', '1593042103]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q03-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1194016923']\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT * FROM {} mt LEFT JOIN population p ON mt.Business_ZIP_Code = p.Zip \".format(MYTABLE)\n",
    "zip_merged = pd.read_sql_query(query, conn)\n",
    "answer = zip_merged.loc[zip_merged['Population'] == zip_merged['Population'].max()]\n",
    "\n",
    "answer = [str(npi) for npi in answer['NPI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(type(answer) == list)\n",
    "assert(answer == ['1194016923'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q04-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PART 4: Total by hospital type\n",
    "\n",
    "This is a multistep process:\n",
    "* From our downloaded data file, compute the `Total payments` per ZIP code and Medicaid EP Hospital Type.\n",
    "* Then merge that with the `population` data to compute a `Total payments` per person.\n",
    "* Then average that across all of the `Medicaid EP Hospital Types` to get an average per persona payment for these type of hospital.\n",
    "\n",
    "Your answer should be in structure of a data frame with at least two columns:\n",
    "* Medicaid_EP_Hospital_Type\n",
    "* Avg_Pay_per_Capita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q04-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Medicaid_EP_Hospital_Type  Avg_Pay_per_Capita\n",
      "0      Acute Care Hospitals          106.582669\n",
      "1      Children's Hospitals          329.550946\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"select Medicaid_EP_Hospital_Type, avg(population_per_zip_code) as Avg_Pay_per_Capita from\n",
    "        (SELECT Medicaid_EP_Hospital_Type,\n",
    "            SUM(total_payments)/Population as population_per_zip_code\n",
    "           FROM {mytable} mt LEFT JOIN population p ON p.ZIP = mt.Business_ZIP_code \n",
    "                    GROUP BY mt.Business_ZIP_code, mt.Medicaid_EP_Hospital_Type)as sub group by Medicaid_EP_Hospital_Type\n",
    "        \"\"\".format(mytable=MYTABLE)\n",
    "\n",
    "answer = pd.read_sql_query(query, conn)\n",
    "print(answer.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q04-tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(type(answer) == pd.core.frame.DataFrame)\n",
    "assert(round(answer.query(\"Medicaid_EP_Hospital_Type == 'Acute Care Hospitals'\")['Avg_Pay_per_Capita'].sum(),3) == 106.583)\n",
    "assert(round(answer.query(\"Medicaid_EP_Hospital_Type == 'Children\\\\'s Hospitals'\")['Avg_Pay_per_Capita'].sum(),3) == 329.551)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Medicaid_EP_Hospital_Type</th>\n",
       "      <th>Avg_Pay_per_Capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acute Care Hospitals</td>\n",
       "      <td>106.582669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children's Hospitals</td>\n",
       "      <td>329.550946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Medicaid_EP_Hospital_Type  Avg_Pay_per_Capita\n",
       "0      Acute Care Hospitals          106.582669\n",
       "1      Children's Hospitals          329.550946"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using Pandas instead of SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytable_df = pd.read_sql_query(\"SELECT * FROM {}\".format(MYTABLE), conn)\n",
    "population_df = pd.read_sql_query(\"SELECT * FROM population\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business_ZIP_Code</th>\n",
       "      <th>Medicaid_EP_Hospital_Type</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>index</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Population</th>\n",
       "      <th>tp_per_population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90004</td>\n",
       "      <td>Acute Care Hospitals</td>\n",
       "      <td>1093021.73</td>\n",
       "      <td>115.0</td>\n",
       "      <td>90004.0</td>\n",
       "      <td>61105.0</td>\n",
       "      <td>17.887599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90012</td>\n",
       "      <td>Acute Care Hospitals</td>\n",
       "      <td>3614739.93</td>\n",
       "      <td>433.0</td>\n",
       "      <td>90012.0</td>\n",
       "      <td>37268.0</td>\n",
       "      <td>96.993129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90015</td>\n",
       "      <td>Acute Care Hospitals</td>\n",
       "      <td>10045484.04</td>\n",
       "      <td>738.0</td>\n",
       "      <td>90015.0</td>\n",
       "      <td>23900.0</td>\n",
       "      <td>420.313140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90017</td>\n",
       "      <td>Acute Care Hospitals</td>\n",
       "      <td>3899845.21</td>\n",
       "      <td>648.0</td>\n",
       "      <td>90017.0</td>\n",
       "      <td>27832.0</td>\n",
       "      <td>140.120912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90020</td>\n",
       "      <td>Children's Hospitals</td>\n",
       "      <td>427640.22</td>\n",
       "      <td>390.0</td>\n",
       "      <td>90020.0</td>\n",
       "      <td>39366.0</td>\n",
       "      <td>10.863187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Business_ZIP_Code Medicaid_EP_Hospital_Type  total_payments  index  \\\n",
       "0              90004      Acute Care Hospitals      1093021.73  115.0   \n",
       "1              90012      Acute Care Hospitals      3614739.93  433.0   \n",
       "2              90015      Acute Care Hospitals     10045484.04  738.0   \n",
       "3              90017      Acute Care Hospitals      3899845.21  648.0   \n",
       "4              90020      Children's Hospitals       427640.22  390.0   \n",
       "\n",
       "       Zip  Population  tp_per_population  \n",
       "0  90004.0     61105.0          17.887599  \n",
       "1  90012.0     37268.0          96.993129  \n",
       "2  90015.0     23900.0         420.313140  \n",
       "3  90017.0     27832.0         140.120912  \n",
       "4  90020.0     39366.0          10.863187  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_df = pd.merge(mytable_df, population_df, left_on='Business_ZIP_Code', right_on='Zip', how='left')\n",
    "\n",
    "total_payments = mytable_df.groupby(['Business_ZIP_Code', 'Medicaid_EP_Hospital_Type'])['total_payments'].sum().to_frame('total_payments').reset_index()\n",
    "tp_merged_df = pd.merge(total_payments, population_df, left_on='Business_ZIP_Code', right_on='Zip', how='left')\n",
    "tp_merged_df['tp_per_population'] = tp_merged_df['total_payments']/tp_merged_df['Population']\n",
    "tp_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medicaid_EP_Hospital_Type\n",
       "Acute Care Hospitals    106.582669\n",
       "Children's Hospitals    329.550946\n",
       "Name: tp_per_population, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pay_per_capita_ht = tp_merged_df.groupby(['Medicaid_EP_Hospital_Type'])['tp_per_population'].mean()\n",
    "avg_pay_per_capita_ht.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "In order to submit your work, you'll need to use the `git` command line program to **add** your homework file (this file) to your local repository, **commit** your changes to your local repository, and then **push** those changes up to github.com.  From there, I'll be able to **pull** the changes down and do my grading.  I'll provide some feedback, **commit** and **push** my comments back to you.  Next week, I'll show you how to **pull** down my comments.\n",
    "\n",
    "To run through everything one last time and submit your work:\n",
    "1. Use the `Kernel` -> `Restart Kernel and Run All Cells` menu option to run everything from top to bottom and stop here.\n",
    "2. Follow the instruction on the prompt below to either ssave and submit your work, or continue working.\n",
    "\n",
    "If anything fails along the way with this submission part of the process, let me know.  I'll help you troubleshoort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Are you ready to submit your work?\n",
      "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
      "2. Type \"yes\" or \"no\" below\n",
      "3. Press Enter\n",
      "\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \n",
      "OK. We can wait.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=input('''\n",
    "Are you ready to submit your work?\n",
    "1. Click the Save icon (or do Ctrl-S / Cmd-S)\n",
    "2. Type \"yes\" or \"no\" below\n",
    "3. Press Enter\n",
    "\n",
    "''')\n",
    "\n",
    "if a=='yes':\n",
    "    !git pull\n",
    "    !git add week15_assignment.ipynb\n",
    "    !git commit -a -m \"Submitting the week 15 programming assignment\"\n",
    "    !git push\n",
    "else:\n",
    "    print('''\n",
    "    \n",
    "OK. We can wait.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
